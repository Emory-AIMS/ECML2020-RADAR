# RADAR: Recurrent Autoencoder BasedDetector for Adversarial Examples onTemporal EHR

## Abstract
Leveraging  the  information-rich  and  large  volume  of  Electronic Health Records (EHR), 
deep learning systems have shown great promise in assisting medical diagnosis and regulatory decisions. 
Although deep learning models have advantages over the traditional machine learning approaches in the medical domain, 
the discovery of adversarial examples has exposed great threats to the state-of-art deep learning medical systems. 
While most of the existing studies are focused on the impact of adversarial perturbation on medical images, 
few works has studied adversarial examples and potential defenses on temporal EHR data. 
In this work,  we  propose  RADAR,  aRecurrent Autoencoder  based Detector forAdversarial examples on temporal EHR data, 
which is the first ef-fort to defend adversarial examples on temporal EHR data. 
We evaluate RADAR on a mortality classifier using the MIMIC-III dataset. 
Experiments show that RADAR can filter out more than 90% of adversarial examples and improve the target model accuracy by more than 90% and F1  score  by  60%.  
Besides,  we  also  propose  an  enhanced  attack  by  introducing  the  distribution  divergence  into  the  loss  function  
such  that the generated adversarial examples are more realistic and difficult to be detected.

## Compatibility
The code is compatible with python 2.7, and tensorflow version >1.4.

## Code Usage

- Train the target classifier
```sh
RNN_train.py --model_name [saved model name]
               --data_path [path to given dataset]
```
- Make adversarial examples. 
```sh
make_adv.py --date 
            --epochs [Training epochs]
            --flip_flag [The stop criteria for creating adversarial examples. True: stop when label flipped; False: stop when noise greater than a threshold]
            --mean_flag [Select between L_1 norm and L_inf norm]
            --t [threshold for stop]
            --alpha [weight for L norm loss]
            --beta [weight for Gaussian Observation loss]
return:
            neg_diff_list.npy
            neg_adv_list.npy
            pos_diff_list.npy
            pos_adv_list.npy
evaluation.py: analysis the adversarial examples
            input: diff_path_neg, diff_path_pos, adv_path_neg, adv_path_pos (generated by make_adv.py)
            returns: statitics such as: KL divergense, Gaussian Observation, L_norm
            
```
- Train RADAR:
```sh
VAE_RNN: the architecture of RADAR
embedder: The embedding structure (a selective block)
VAE_train_v2.py --data
                --epochs [Training epochs]
                --alpha [weight for loss]
                --beta [weight for loss]
                --lr [learning rate]                
                
``` 
- Evaluate RADAR:
```
get_threshould.py: --date
                   --tile [allowing how much percentile of clean example to pass]
                   other input: model_path, pos_clean_path, neg_clean_path, pos_clean_path, neg_clean_path
                   return the index of examples that pass RADAR 
RNN_test.py: evaluate the target model performance               
``` 
